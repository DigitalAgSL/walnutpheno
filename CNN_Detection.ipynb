{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "786939216cbc4703b598d373af777dea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_366f077c98674d3b993a21ee27c39d7e",
              "IPY_MODEL_0b9902a6a9894359964a73cead769660",
              "IPY_MODEL_e5cef554883a4433b20df41b0af98623"
            ],
            "layout": "IPY_MODEL_8d0c2a2bcda249f0a8b474a08689547f"
          }
        },
        "366f077c98674d3b993a21ee27c39d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de688d179ac4da4add851f993a74083",
            "placeholder": "​",
            "style": "IPY_MODEL_74e0e7affc374d27ad63d07ecece6457",
            "value": "100%"
          }
        },
        "0b9902a6a9894359964a73cead769660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8641afcc68964d6c818a9c3f3035bc30",
            "max": 178090079,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3489545fa1aa49818c348031ea450f39",
            "value": 178090079
          }
        },
        "e5cef554883a4433b20df41b0af98623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100b2a7d79444884ac7fcaab6b394654",
            "placeholder": "​",
            "style": "IPY_MODEL_1a611df1bca34d939d53d668bb5d0da6",
            "value": " 170M/170M [00:00&lt;00:00, 243MB/s]"
          }
        },
        "8d0c2a2bcda249f0a8b474a08689547f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de688d179ac4da4add851f993a74083": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74e0e7affc374d27ad63d07ecece6457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8641afcc68964d6c818a9c3f3035bc30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3489545fa1aa49818c348031ea450f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100b2a7d79444884ac7fcaab6b394654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a611df1bca34d939d53d668bb5d0da6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "53ByOJEDFV9R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07cf8789-b6b5-4f3b-e87d-c4c12374a2c4"
      },
      "source": [
        "#google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/wka')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " 2020_A46.json\n",
            " 2020_A46.xml\n",
            " 2020_A50.json\n",
            " 2020_A50.xml\n",
            " 2020_A53.json\n",
            " 2020_A53.xml\n",
            " 2020_A59.json\n",
            " 2020_A59.xml\n",
            " 2020_A90.json\n",
            " 2020_A90.xml\n",
            " 2020_B05.json\n",
            " 2020_B05.xml\n",
            " 2020_C04.json\n",
            " 2020_C04.xml\n",
            " 2020_F010.json\n",
            " 2020_F010.xml\n",
            " 2020_F021.json\n",
            " 2020_F021.xml\n",
            " 2020_F036.json\n",
            " 2020_F036.xml\n",
            " 2020_F203.json\n",
            " 2020_F203.xml\n",
            " 2020_F262.json\n",
            " 2020_F262.xml\n",
            " 2020_F300.json\n",
            " 2020_F300.xml\n",
            "'5_Walnut Project.json'\n",
            " annotated_images\n",
            " annotations_2020_a59.json\n",
            " area.png\n",
            " bboxes_images\n",
            " bbox_inference.py\n",
            " CNN_Walnut_1042020_2019WalnutDryerExp.csv\n",
            " CNN_Walnut_12022020_2017.csv\n",
            " CNN_Walnut_12042020_2018.csv\n",
            " CNN_Walnut_12042020_2019.csv\n",
            " CNN_Walnut_12042020_2019PlasticBagExp.csv\n",
            " CNN_Walnut_12042020_30DegreeRoomExp_2017.csv\n",
            " coco_eval.py\n",
            " coco_utils.py\n",
            " colabDetect.ipynb\n",
            " config.py\n",
            " cvat_xml_masks.ipynb\n",
            " cvat_xml_masks.py\n",
            " datatools.py\n",
            " detect.py\n",
            " engine.py\n",
            " evaluate_model.py\n",
            " generate_masks.py\n",
            " GoogleColabBasics_CNNWalnut.docx\n",
            " inference.py\n",
            " instances.png\n",
            " LICENSE\n",
            " logs.txt\n",
            " new_final_model.pth\n",
            "'New Model'\n",
            " old_final_model.pth\n",
            "'Old Model'\n",
            "'Old vs new model'\n",
            " output\n",
            " plot_gt_masks.py\n",
            " predicted_masks\n",
            " prediction_mask.py\n",
            " predictions\n",
            " __pycache__\n",
            " pytorch.yml\n",
            " README.md\n",
            " SL_Test.ipynb\n",
            " test\n",
            " train\n",
            " training_pipeline.py\n",
            " utils.py\n",
            " validate\n",
            " walnut_images\n",
            " wlnt_detection_results\n",
            " wlnt_im_test\n",
            " xmls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wPYJKfGF2Q4"
      },
      "source": [
        "#Imports\n",
        "# Mask R-CNN\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import math\n",
        "import re\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "# # sys.path.append(ROOT_DIR)  # To find local version of the library\n",
        "from datatools import GrapeBunchDataset\n",
        "import datatools as dtools\n",
        "# import utils\n",
        "# from engine import evaluate\n",
        "import skimage.io\n",
        "import pandas as pd\n",
        "# scikit image region properties\n",
        "from skimage import color\n",
        "from skimage import data, util, measure\n",
        "from skimage.measure import label, regionprops, regionprops_table\n",
        "\n",
        "#for generating masks\n",
        "import predicted_masks\n",
        "\n",
        "#*********************************************************************\n",
        "#from prediction_mask.py\n",
        "from PIL import Image\n",
        "from glob import glob\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "sys.path.append(os.path.join(sys.path[0]))  # To find local version of the library\n",
        "# from datatools import GrapeBunchDataset\n",
        "# import datatools as dtools\n",
        "import utils\n",
        "from engine import evaluate\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "import torch\n",
        "import warnings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "786939216cbc4703b598d373af777dea",
            "366f077c98674d3b993a21ee27c39d7e",
            "0b9902a6a9894359964a73cead769660",
            "e5cef554883a4433b20df41b0af98623",
            "8d0c2a2bcda249f0a8b474a08689547f",
            "6de688d179ac4da4add851f993a74083",
            "74e0e7affc374d27ad63d07ecece6457",
            "8641afcc68964d6c818a9c3f3035bc30",
            "3489545fa1aa49818c348031ea450f39",
            "100b2a7d79444884ac7fcaab6b394654",
            "1a611df1bca34d939d53d668bb5d0da6"
          ]
        },
        "id": "A-UIIlxUGHjO",
        "outputId": "5eb16d6c-155f-4b65-f8ea-604a31bd7aa2"
      },
      "source": [
        "#prediction deffinitions and settings\n",
        "print('prediction deffinitions and settings')\n",
        "warnings.filterwarnings('ignore')\n",
        "CLASS_NAMES = ['__background__', 'Walnut']\n",
        "device = torch.device('cuda')\n",
        "num_classes=2\n",
        "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True, rpn_nms_thresh=0.15, box_nms_thresh=0.05) # deafult nms thresholds = 0.5, 0.7\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    # now get the number of input features for the mask classifier\n",
        "in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "hidden_layer = 256\n",
        "    # and replace the mask predictor with a new one\n",
        "model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "# model.load_state_dict(torch.load('final_model_sky_2.pth'), strict=False)   # the name of your saved model, should be 'best_model.pth' by default\n",
        "# model.eval()\n",
        "state_dict = torch.load( \"new_final_model.pth\")\n",
        "model.load_state_dict(state_dict)\n",
        "model.to('cuda')\n",
        "model.eval()\n",
        "# # Aply mask\n",
        "#     for c in range(3):\n",
        "#         image[:, :, c] = np.where(mask > 0.5,image[:, :, c] * (1 - alpha) + alpha * color[c] * 255, image[:, :, c])\n",
        "#     return image\n",
        "\n",
        "def get_prediction(img_path, confidence):\n",
        "    \"\"\"\n",
        "    get_prediction\n",
        "      parameters:\n",
        "        - img_path - path of the input image\n",
        "        - confidence - threshold to keep the prediction or not\n",
        "      method:\n",
        "        - Image is obtained from the image path\n",
        "        - the image is converted to image tensor using PyTorch's Transforms\n",
        "        - image is passed through the model to get the predictions\n",
        "        - masks, classes and bounding boxes are obtained from the model and soft masks are made binary(0 or 1) on masks\n",
        "          ie: eg. segment of cat is made 1 and rest of the image is made 0\n",
        "    \"\"\"\n",
        "    img = Image.open(img_path)\n",
        "    transform = T.Compose([T.ToTensor()])\n",
        "    img = transform(img)\n",
        "    img = img.to(device)\n",
        "    pred = model([img])\n",
        "    pred_score = list(pred[0]['scores'].detach().cpu().numpy())\n",
        "    pred_t = [pred_score.index(x) for x in pred_score if x>confidence][-1]\n",
        "    masks = (pred[0]['masks']>confidence).squeeze().detach().cpu().numpy()\n",
        "    # print(pred[0]['labels'].numpy().max())\n",
        "    pred_class = [CLASS_NAMES[i] for i in list(pred[0]['labels'].cpu().numpy())]\n",
        "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().cpu().numpy())]\n",
        "    masks = masks[:pred_t+1]\n",
        "    pred_boxes = pred_boxes[:pred_t+1]\n",
        "    pred_class = pred_class[:pred_t+1]\n",
        "\n",
        "\n",
        "    return masks , pred_boxes, pred_class, pred_score\n",
        "\n",
        "#*********************************************************************\n",
        "\n",
        "# Create final data tabel calsses dictionay\n",
        "final_df = pd.DataFrame()\n",
        "attribute_dic = {'class_ids':[], 'area':[]} #*#\n",
        "\n",
        "print('end predictions and settings')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction deffinitions and settings\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /root/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/170M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "786939216cbc4703b598d373af777dea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "end predictions and settings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfBOf6cAhQ7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28393efa-6fa0-48f1-99cc-6ad96c1d7ac4"
      },
      "source": [
        "\n",
        "#***************************loop for processing imgs in walnut_images directory ***************************\n",
        "# iteartivly process the images. 0 to ~ 100 walnuts per image\n",
        "print('iteartivly process the images. 0 to ~ 100 walnuts per image')\n",
        "\n",
        "wlnt_path = 'walnut_images/'\n",
        "wlnt_dir = os.listdir('walnut_images')\n",
        "for i, wlnt_img in enumerate(wlnt_dir):\n",
        "    #print('image' ,i)\n",
        "\n",
        "    #Iniate color space higherarchical data frame\n",
        "    iterables = [['lab','rgb'], ['x','y','z'], ['10','25','50','75','90']]\n",
        "    tab_idx = pd.MultiIndex.from_product(iterables, names=['color_space','channel','percentile'])\n",
        "    walnut_colors_df = pd.DataFrame(columns=tab_idx)\n",
        "    color_spaces = ['lab','rgb']\n",
        "    channels = ['x','y','z']\n",
        "    percentiles = ['10','25','50','75','90']\n",
        "\n",
        "    img_path = wlnt_path + wlnt_img\n",
        "    original_image = plt.imread(img_path)\n",
        "    #tensor_image = torch.from_numpy(np_image)\n",
        "\n",
        "#*********************************************************************\n",
        "\n",
        "    # results of inference on one image as boolian masks\n",
        "    masks, boxes, pred_class, score = get_prediction(img_path, confidence = 0.5)\n",
        "\n",
        "#*********************************************************************\n",
        "\n",
        "\n",
        "#***************************Finds mask's and masked image's attributes******************************************\n",
        "\n",
        "    #Finds each mask's centroids and area\n",
        "    mask_centroid_x = [None] * (masks.shape[0])\n",
        "    mask_centroid_y = [None] * (masks.shape[0])\n",
        "\n",
        "    mask_area =  area_cv2 = perimeter_cv2 = [None] * (masks.shape[0])\n",
        "\n",
        "\n",
        "    for k in range(masks.shape[0]):\n",
        "        mask_bool = (masks[k,:,:]).astype(np.float32)\n",
        "        Moments = cv2.moments(mask_bool)\n",
        "        mask_centroid_x[k] = int((Moments[\"m10\"]/Moments[\"m00\"]))  #rounded to nearest whole pixel value.\n",
        "        mask_centroid_y[k] = int((Moments[\"m01\"]/Moments[\"m00\"]))\n",
        "\n",
        "\n",
        "        mask_area[k] = np.sum(masks[k,:,:])\n",
        "        #area_cv2[k] = cv2.contourArea(mask_bool)\n",
        "        #perimeter_cv2[k] = cv2.arcLength(mask_bool*1,True)\n",
        "        #mean_val_cv2 = cv.mean(rgb_img,mask = mask_bool)\n",
        "\n",
        "\n",
        "    temp1 = np.array(original_image)\n",
        "    #temp1 = skimage.io.imread('walnut_images/' + wlnt_img)\n",
        "\n",
        "    #sum of all walnut masks in one image\n",
        "    sum_masks = np.sum(masks,axis=0)\n",
        "    sum_masks_3d = np.expand_dims(sum_masks,2)\n",
        "    temp_masked = sum_masks_3d*temp1\n",
        "\n",
        "    # Image color space conversion\n",
        "    grayscale = color.rgb2gray(temp_masked)\n",
        "    lab_img = cv2.cvtColor(temp1, cv2.COLOR_BGR2LAB)\n",
        "    #lab_img = color.rgb2lab(temp1)\n",
        "    #lab_img = color.rgb2lab(temp_masked)\n",
        "    #hsv_img = color.rgb2hsv(sum_masks)\n",
        "\n",
        "    #Scikit image anlysis\n",
        "    # label_img = label(sum_masks)\n",
        "    # regions = regionprops(label_img)\n",
        "    # props = regionprops_table(label_img, intensity_image=grayscale, properties=('label', 'bbox','centroid', 'area', 'orientation',\n",
        "    #         'major_axis_length', 'minor_axis_length','perimeter',  'max_intensity','min_intensity',\n",
        "    #         'mean_intensity','equivalent_diameter','filled_area'))\n",
        "\n",
        "    # Skiimg region properties data frame\n",
        "    # scikit_data_table = pd.DataFrame(props)\n",
        "    #scikit_data_table = scikit_data_table[scikit_data_table[\"area\"] >1600]\n",
        "\n",
        "    rgb_temp = temp1.copy()\n",
        "    lab_temp = lab_img\n",
        "    # Finds Percentiles\n",
        "    #for k, mask_label in enumerate(np.unique(label_img)[1:]):\n",
        "    for k in range(masks.shape[0]):\n",
        "    #for k, mask_label in enumerate(np.array(scikit_data_table['label'])):\n",
        "        #idx = label_img == mask_label\n",
        "        idx = masks[k,:,:]\n",
        "        rgb_temp = temp1.copy()*np.dstack([idx,idx,idx])\n",
        "        lab_temp = lab_img.copy()*np.dstack([idx,idx,idx])\n",
        "\n",
        "        # Gausian distribution/percentile of walnut colors\n",
        "        # Removes 0's from masked image and and retuns a 1 pixel wide image wth all the non zero values\n",
        "        # 1D Rgb remove empty Pixels\n",
        "        rgb_remove = rgb_temp[rgb_temp[:,:, 0] != 0]\n",
        "        rgb_remove = rgb_remove[rgb_remove[:, 1] != 0]\n",
        "        rgb_remove = rgb_remove[rgb_remove[:, 2] != 0]\n",
        "        rgb_remove = np.expand_dims(rgb_remove,1)\n",
        "\n",
        "        # 1D Lab Rgb remove empty Pixels\n",
        "        lab_remove = lab_temp[lab_temp[:,:,0] != 0]\n",
        "        lab_remove = lab_remove[lab_remove[:, 1] != 0]\n",
        "        lab_remove = lab_remove[lab_remove[:, 2] != 0]\n",
        "        lab_remove = np.expand_dims(lab_remove,1)\n",
        "\n",
        "        # Populates colors data table ~3000 calculations of np.percentile()\n",
        "        for ii in color_spaces:\n",
        "            if ii == 'lab':\n",
        "                for nn,jj in enumerate(channels):\n",
        "                    for rr,kk in enumerate(percentiles):\n",
        "                        walnut_colors_df.loc[k,(ii,jj,kk)] = np.percentile(lab_remove[:,:,nn], q = int(percentiles[rr]))\n",
        "            elif ii == 'rgb':\n",
        "                for nn,jj in enumerate(channels):\n",
        "                    for rr,kk in enumerate(percentiles):\n",
        "                        walnut_colors_df.loc[k,(ii,jj,kk)] = np.percentile(rgb_remove[:,:,nn], q = int(percentiles[rr]))\n",
        "\n",
        "    #add labels\n",
        "    # color_label = np.array(scikit_data_table['label'])\n",
        "    color_label = np.array(range(masks.shape[0]))\n",
        "    walnut_colors_df.insert(0,'label', color_label)\n",
        "\n",
        "    # print(\"masking:\", end-start)\n",
        "    # print(\"color loop:\", end_ii-start_ii)\n",
        "    # print(\"percentiles:\", end_k- start_k)\n",
        "    # print(\"sci&color\", end_i - start_i)\n",
        "\n",
        "\n",
        "    #********* class types and ids fidning areas for merge\n",
        "    # attribute_dic['class_ids'] = pred_class\n",
        "    # #attribute_dic['class_ids'] = results[0]['class_ids']\n",
        "    # attribute_dic['area'] = mask_area\n",
        "    # class_df = pd.DataFrame(attribute_dic)\n",
        "\n",
        "    #adjust walnut_color_df labels\n",
        "    walnut_colors_df.columns = walnut_colors_df.columns.map('_'.join).str.strip('_')\n",
        "\n",
        "    #Inserts additonal atrributes to datatable\n",
        "    walnut_colors_df.insert(1,'class_ids',pred_class)\n",
        "    walnut_colors_df.insert(2,'centroid_x', mask_centroid_x)\n",
        "    walnut_colors_df.insert(3,'centroid_y', mask_centroid_y)\n",
        "    walnut_colors_df.insert(4,'area', mask_area)\n",
        "    #walnut_colors_df.insert(5,'perimeter_cv2', perimeter_cv2)\n",
        "    #walnut_colors_df.insert(6,'area_cv2',area_cv2)\n",
        "\n",
        "    temp_datatable = walnut_colors_df\n",
        "\n",
        "    # append lists of scikit and colors dfs an image id\n",
        "    # walnut_colors_list.append(walnut_colors_df)\n",
        "    # scikit_list.append(scikit_data_table)\n",
        "    # Image_id_list.append(image_id)\n",
        "\n",
        "    # Combined data table\n",
        "    # temp_datatable = walnut_colors_df.merge(scikit_data_table)\n",
        "    #temp_datatable = temp_datatable.merge(class_df)\n",
        "\n",
        "    #temp_datatable = pd.concat([scikit_data_table, walnut_colors_df], axis=1)\n",
        "\n",
        "    # attribute_ids = results[0]['class_ids']\n",
        "    # temp_datatable.insert(0, 'class_ids', class_ids)\n",
        "\n",
        "    image_id = str(wlnt_dir[i][:-4])\n",
        "    temp_datatable.insert(0, 'image_id', image_id)\n",
        "\n",
        "    #remove Nans\n",
        "\n",
        "   # print(\"10:\", time.clock() )\n",
        "    final_df = pd.concat([final_df, temp_datatable], axis=0)\n",
        "\n",
        "    #final_df.append(temp_datatable)\n",
        "\n",
        "#Concatinate df outside of loop\n",
        "#concatinate all scikit_data_tables to repective walnutcolors_df, and image id's\n",
        "\n",
        "# plt.imshow(mask_bool)\n",
        "# plt.scatter(mask_centroid_x[k],mask_centroid_y[k])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteartivly process the images. 0 to ~ 100 walnuts per image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDfw6bPuHGla",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94b56da3-9ed0-46ec-d1d9-2d94f00d4672"
      },
      "source": [
        "#convert to long format and csv\n",
        "final_walnut_df = pd.melt(final_df, id_vars=['image_id', 'label'])\n",
        "\n",
        "csv_path =  'wlnt_detection_results/'\n",
        "\n",
        "name = 'magick_2022'\n",
        "print('convert to long format and csv' )\n",
        "\n",
        "if name:\n",
        "    final_walnut_df.to_csv(csv_path + name + '.csv')\n",
        "else:\n",
        "    final_walnut_df.to_csv(csv_path + time.asctime() +'.csv')\n",
        "\n",
        "\n",
        "# # %%\n",
        "# #last image masked. Maskrcnn\n",
        "# test_image = original_image.copy()\n",
        "# for c in range(3):\n",
        "#     test_image[:, :, c] = np.where(sum_masks < 0.5, test_image[:, :, c] * 0, test_image[:, :, c])\n",
        "#plt.imshow(test_image)\n",
        "#\n",
        "# #last image scikit labels. Maskrcnn + scikit image\n",
        "# image_label_overlay = color.label2rgb(label_img, image=original_image, bg_label=0)\n",
        "\n",
        "# #instace segmentation from MaskRCNN\n",
        "# test_image = original_image.copy()\n",
        "# mask_label = 0\n",
        "# for c in range(3):\n",
        "#     test_image[:, :, c] = np.where(masks[mask_label,:,:] < 0.5, test_image[:, :, c] * 0, test_image[:, :, c])\n",
        "\n",
        "# #instace from scikit labels\n",
        "#test_image = original_image.copy()\n",
        "# scikit_label = 1\n",
        "# for c in range(3):\n",
        "#     test_img[:, :, c] = np.where(label_img != scikit_label, test_img[:, :, c]*0, test_img[:, :, c])\n",
        "#plt.imshow(test_img)\n",
        "# %%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "convert to long format and csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnmJCgXYyXGl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "1111723a-cb68-46e8-c628-3e3bcbb4685c"
      },
      "source": [
        "#Visualize and animate\n",
        "%matplotlib inline\n",
        "from matplotlib import animation, rc\n",
        "\n",
        "rc('animation', html='html5')\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.set_xlim( 0, mask_bool.shape(0))\n",
        "ax.set_ylim(0, mask_bool.shape(1))\n",
        "\n",
        "#masked_idx, = ax.imshow()\n",
        "masked_idx, = ax.plot([], [])\n",
        "cent_idx, = ax.scatter([], [])\n",
        "\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    return (line,)\n",
        "\n",
        "def animate(i):\n",
        "    x = np.linspace(0, 2, 1000)\n",
        "    y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
        "    line.set_data(x, y)\n",
        "    return (line,)\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=100, interval=20, blit=True)\n",
        "anim\n",
        "\n",
        "#image * mask + scatter of coordinates\n",
        "\n",
        "#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-17949f67b312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_bool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_bool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}